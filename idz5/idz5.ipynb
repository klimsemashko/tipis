{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "lv7P_WIBG5WC",
        "outputId": "0e596f88-cef5-477b-a9f5-7a580bb78c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63215d8c-9b02-4a83-8f5a-c16804013878\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63215d8c-9b02-4a83-8f5a-c16804013878\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving jamb_exam_results.csv to jamb_exam_results (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "df = pd.read_csv('jamb_exam_results.csv')\n",
        "\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "df = df.drop(columns=['student_id'])\n",
        "\n",
        "df = df.fillna(0)\n",
        "\n",
        "X = df.drop(columns=['jamb_score'])\n",
        "y = df['jamb_score']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
        "\n",
        "dv = DictVectorizer(sparse=True)\n",
        "\n",
        "X_train_dict = X_train.to_dict(orient='records')\n",
        "X_val_dict = X_val.to_dict(orient='records')\n",
        "X_test_dict = X_test.to_dict(orient='records')\n",
        "\n",
        "X_train_encoded = dv.fit_transform(X_train_dict)\n",
        "X_val_encoded = dv.transform(X_val_dict)\n",
        "X_test_encoded = dv.transform(X_test_dict)"
      ],
      "metadata": {
        "id": "LG3Q3QqoHAeB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 1"
      ],
      "metadata": {
        "id": "Tx_kbGIxHbZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "model_tree = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
        "model_tree.fit(X_train_encoded, y_train)\n",
        "\n",
        "best_split_feature = model_tree.feature_importances_\n",
        "best_split_idx = best_split_feature.argmax()\n",
        "best_feature_name = dv.get_feature_names_out()[best_split_idx]\n",
        "\n",
        "print(f\"Признак для разбиения: {best_feature_name}\")"
      ],
      "metadata": {
        "id": "_ta83_zCHciE",
        "outputId": "1379f9c7-e17d-4160-d0b2-8f4a7766fd15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Признак для разбиения: study_hours_per_week\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 2"
      ],
      "metadata": {
        "id": "N03LrD4nHjEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "model_rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
        "model_rf.fit(X_train_encoded, y_train)\n",
        "\n",
        "y_val_pred_rf = model_rf.predict(X_val_encoded)\n",
        "\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "print(f\"RMSE на валидационном наборе: {rmse_rf:.2f}\")"
      ],
      "metadata": {
        "id": "ogscS9z6Hh2s",
        "outputId": "d429d6bd-7ae0-48ee-8315-af5ac2d4cc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE на валидационном наборе: 43.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 3"
      ],
      "metadata": {
        "id": "qDLAtXV-HpQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators_values = range(10, 201, 10)\n",
        "rmse_values = []\n",
        "\n",
        "for n_estimators in n_estimators_values:\n",
        "    model_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=1, n_jobs=-1)\n",
        "    model_rf.fit(X_train_encoded, y_train)\n",
        "\n",
        "    y_val_pred_rf = model_rf.predict(X_val_encoded)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "    rmse_values.append(rmse)\n",
        "\n",
        "optimal_n_estimators = n_estimators_values[np.argmin(rmse_values)]\n",
        "print(f\"Лучшее значение n_estimators: {optimal_n_estimators} с RMSE: {min(rmse_values):.3f}\")"
      ],
      "metadata": {
        "id": "9UjaI1nsHqEB",
        "outputId": "bd9f28e2-24fe-4d63-d2ee-9eb2d51a1ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение n_estimators: 180 с RMSE: 40.136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 4"
      ],
      "metadata": {
        "id": "Ki7oO8FwHuKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth_values = [10, 15, 20, 25]\n",
        "n_estimators_values = range(10, 201, 10)\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_max_depth = None\n",
        "best_n_estimators = None\n",
        "\n",
        "for max_depth in max_depth_values:\n",
        "    for n_estimators in n_estimators_values:\n",
        "        model_rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=1, n_jobs=-1)\n",
        "        model_rf.fit(X_train_encoded, y_train)\n",
        "\n",
        "        y_val_pred_rf = model_rf.predict(X_val_encoded)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_max_depth = max_depth\n",
        "            best_n_estimators = n_estimators\n",
        "\n",
        "print(f\"Лучшее значение max_depth: {best_max_depth}, n_estimators: {best_n_estimators} с RMSE: {best_rmse:.3f}\")"
      ],
      "metadata": {
        "id": "BsGWy4ZgHu3b",
        "outputId": "824d84ac-2967-4b8a-f83d-c2e42e3023b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение max_depth: 10, n_estimators: 180 с RMSE: 39.823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 5"
      ],
      "metadata": {
        "id": "0pwJhoIaHxt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
        "model_rf.fit(X_train_encoded, y_train)\n",
        "\n",
        "feature_importances = model_rf.feature_importances_\n",
        "most_important_feature_idx = feature_importances.argmax()\n",
        "most_important_feature_name = dv.get_feature_names_out()[most_important_feature_idx]\n",
        "\n",
        "print(f\"Самый важный признак: {most_important_feature_name}\")"
      ],
      "metadata": {
        "id": "bqnjQPJdHyvR",
        "outputId": "72ebd99e-cc86-4145-fa82-19fd70cf0f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Самый важный признак: study_hours_per_week\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вопрос 6"
      ],
      "metadata": {
        "id": "a9pTcQhEH2WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_encoded, label=y_train)\n",
        "dval = xgb.DMatrix(X_val_encoded, label=y_val)\n",
        "\n",
        "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.3,\n",
        "    'max_depth': 6,\n",
        "    'min_child_weight': 1,\n",
        "    'objective': 'reg:squarederror',\n",
        "    'nthread': 8,\n",
        "    'seed': 1,\n",
        "    'verbosity': 1,\n",
        "}\n",
        "\n",
        "model_xgb = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
        "\n",
        "y_val_pred_xgb = model_xgb.predict(dval)\n",
        "rmse_xgb_0_3 = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
        "print(f\"RMSE для eta=0.3: {rmse_xgb_0_3:.3f}\")\n",
        "\n",
        "xgb_params['eta'] = 0.1\n",
        "model_xgb = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
        "\n",
        "y_val_pred_xgb = model_xgb.predict(dval)\n",
        "rmse_xgb_0_1 = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
        "print(f\"RMSE для eta=0.1: {rmse_xgb_0_1:.3f}\")\n",
        "\n",
        "if rmse_xgb_0_3 < rmse_xgb_0_1:\n",
        "    print(\"Лучшее значение eta: 0.3\")\n",
        "else:\n",
        "    print(\"Лучшее значение eta: 0.1\")"
      ],
      "metadata": {
        "id": "t9qDYxRAH3Jm",
        "outputId": "dc2a9f70-18d5-4af2-fd98-700237a4f74e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-rmse:42.84835\teval-rmse:44.52338\n",
            "[1]\ttrain-rmse:39.96423\teval-rmse:42.83406\n",
            "[2]\ttrain-rmse:37.91231\teval-rmse:41.62607\n",
            "[3]\ttrain-rmse:36.51126\teval-rmse:41.25491\n",
            "[4]\ttrain-rmse:35.52212\teval-rmse:40.84075\n",
            "[5]\ttrain-rmse:34.77126\teval-rmse:40.71677\n",
            "[6]\ttrain-rmse:34.03898\teval-rmse:40.72669\n",
            "[7]\ttrain-rmse:33.62820\teval-rmse:40.68822\n",
            "[8]\ttrain-rmse:32.94729\teval-rmse:40.81273\n",
            "[9]\ttrain-rmse:32.27703\teval-rmse:40.84939\n",
            "[10]\ttrain-rmse:31.73818\teval-rmse:40.83759\n",
            "[11]\ttrain-rmse:31.31360\teval-rmse:40.80575\n",
            "[12]\ttrain-rmse:30.72949\teval-rmse:40.84238\n",
            "[13]\ttrain-rmse:30.11486\teval-rmse:40.96020\n",
            "[14]\ttrain-rmse:29.43538\teval-rmse:40.98775\n",
            "[15]\ttrain-rmse:29.23018\teval-rmse:41.04798\n",
            "[16]\ttrain-rmse:28.64113\teval-rmse:41.08375\n",
            "RMSE для eta=0.3: 41.160\n",
            "[0]\ttrain-rmse:45.64414\teval-rmse:46.63724\n",
            "[1]\ttrain-rmse:44.26862\teval-rmse:45.58724\n",
            "[2]\ttrain-rmse:43.08569\teval-rmse:44.76209\n",
            "[3]\ttrain-rmse:42.05227\teval-rmse:44.02498\n",
            "[4]\ttrain-rmse:41.10533\teval-rmse:43.40640\n",
            "[5]\ttrain-rmse:40.28309\teval-rmse:42.92195\n",
            "[6]\ttrain-rmse:39.54133\teval-rmse:42.49211\n",
            "[7]\ttrain-rmse:38.87686\teval-rmse:42.15780\n",
            "[8]\ttrain-rmse:38.27674\teval-rmse:41.84104\n",
            "[9]\ttrain-rmse:37.74058\teval-rmse:41.58026\n",
            "[10]\ttrain-rmse:37.26338\teval-rmse:41.35829\n",
            "[11]\ttrain-rmse:36.82810\teval-rmse:41.19143\n",
            "[12]\ttrain-rmse:36.41091\teval-rmse:41.02571\n",
            "[13]\ttrain-rmse:36.01019\teval-rmse:40.90308\n",
            "[14]\ttrain-rmse:35.67454\teval-rmse:40.79701\n",
            "[15]\ttrain-rmse:35.33492\teval-rmse:40.66274\n",
            "[16]\ttrain-rmse:35.01425\teval-rmse:40.60840\n",
            "[17]\ttrain-rmse:34.72687\teval-rmse:40.55942\n",
            "[18]\ttrain-rmse:34.40588\teval-rmse:40.46321\n",
            "[19]\ttrain-rmse:34.16207\teval-rmse:40.42760\n",
            "[20]\ttrain-rmse:33.94837\teval-rmse:40.40272\n",
            "[21]\ttrain-rmse:33.67900\teval-rmse:40.33790\n",
            "[22]\ttrain-rmse:33.44365\teval-rmse:40.25893\n",
            "[23]\ttrain-rmse:33.15283\teval-rmse:40.23702\n",
            "[24]\ttrain-rmse:32.93544\teval-rmse:40.23146\n",
            "[25]\ttrain-rmse:32.76647\teval-rmse:40.16645\n",
            "[26]\ttrain-rmse:32.63384\teval-rmse:40.17172\n",
            "[27]\ttrain-rmse:32.48413\teval-rmse:40.20266\n",
            "[28]\ttrain-rmse:32.34090\teval-rmse:40.20407\n",
            "[29]\ttrain-rmse:32.10350\teval-rmse:40.20207\n",
            "[30]\ttrain-rmse:31.97085\teval-rmse:40.20269\n",
            "[31]\ttrain-rmse:31.73414\teval-rmse:40.22897\n",
            "[32]\ttrain-rmse:31.54401\teval-rmse:40.19830\n",
            "[33]\ttrain-rmse:31.36899\teval-rmse:40.20204\n",
            "[34]\ttrain-rmse:31.24775\teval-rmse:40.23194\n",
            "RMSE для eta=0.1: 40.257\n",
            "Лучшее значение eta: 0.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Добро пожаловать в Colaboratory!",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}